{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = pd.read_json('quotes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quote         48391\n",
       "Author        48391\n",
       "Tags          48391\n",
       "Popularity    48391\n",
       "Category      48391\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = quotes.sort_values(['Quote'])[287:-400].drop_duplicates(['Quote'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quote         36359\n",
       "Author        36359\n",
       "Tags          36359\n",
       "Popularity    36359\n",
       "Category      36359\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inspiration</th>\n",
       "      <td>4087</td>\n",
       "      <td>4087</td>\n",
       "      <td>4087</td>\n",
       "      <td>4087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humor</th>\n",
       "      <td>3094</td>\n",
       "      <td>3094</td>\n",
       "      <td>3094</td>\n",
       "      <td>3094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>2748</td>\n",
       "      <td>2748</td>\n",
       "      <td>2748</td>\n",
       "      <td>2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>2731</td>\n",
       "      <td>2731</td>\n",
       "      <td>2731</td>\n",
       "      <td>2731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>success</th>\n",
       "      <td>1867</td>\n",
       "      <td>1867</td>\n",
       "      <td>1867</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philosophy</th>\n",
       "      <td>1799</td>\n",
       "      <td>1799</td>\n",
       "      <td>1799</td>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hope</th>\n",
       "      <td>1737</td>\n",
       "      <td>1737</td>\n",
       "      <td>1737</td>\n",
       "      <td>1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1372</td>\n",
       "      <td>1372</td>\n",
       "      <td>1372</td>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arts</th>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books</th>\n",
       "      <td>915</td>\n",
       "      <td>915</td>\n",
       "      <td>915</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quotes</th>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>881</td>\n",
       "      <td>881</td>\n",
       "      <td>881</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writing</th>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happiness</th>\n",
       "      <td>836</td>\n",
       "      <td>836</td>\n",
       "      <td>836</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truth</th>\n",
       "      <td>827</td>\n",
       "      <td>827</td>\n",
       "      <td>827</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poetry</th>\n",
       "      <td>755</td>\n",
       "      <td>755</td>\n",
       "      <td>755</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faith</th>\n",
       "      <td>753</td>\n",
       "      <td>753</td>\n",
       "      <td>753</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wisdom</th>\n",
       "      <td>753</td>\n",
       "      <td>753</td>\n",
       "      <td>753</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>god</th>\n",
       "      <td>743</td>\n",
       "      <td>743</td>\n",
       "      <td>743</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>733</td>\n",
       "      <td>733</td>\n",
       "      <td>733</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>715</td>\n",
       "      <td>715</td>\n",
       "      <td>715</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge</th>\n",
       "      <td>703</td>\n",
       "      <td>703</td>\n",
       "      <td>703</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>668</td>\n",
       "      <td>668</td>\n",
       "      <td>668</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friendship</th>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soul</th>\n",
       "      <td>567</td>\n",
       "      <td>567</td>\n",
       "      <td>567</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>530</td>\n",
       "      <td>530</td>\n",
       "      <td>530</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mind</th>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motivation</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Quote  Author  Tags  Popularity\n",
       "Category                                     \n",
       "inspiration    4087    4087  4087        4087\n",
       "humor          3094    3094  3094        3094\n",
       "life           2748    2748  2748        2748\n",
       "love           2731    2731  2731        2731\n",
       "success        1867    1867  1867        1867\n",
       "philosophy     1799    1799  1799        1799\n",
       "hope           1737    1737  1737        1737\n",
       "               1372    1372  1372        1372\n",
       "arts            962     962   962         962\n",
       "books           915     915   915         915\n",
       "quotes          912     912   912         912\n",
       "education       881     881   881         881\n",
       "writing         860     860   860         860\n",
       "happiness       836     836   836         836\n",
       "truth           827     827   827         827\n",
       "death           799     799   799         799\n",
       "romance         792     792   792         792\n",
       "poetry          755     755   755         755\n",
       "faith           753     753   753         753\n",
       "wisdom          753     753   753         753\n",
       "god             743     743   743         743\n",
       "science         733     733   733         733\n",
       "funny           715     715   715         715\n",
       "knowledge       703     703   703         703\n",
       "religion        672     672   672         672\n",
       "relationship    668     668   668         668\n",
       "friendship      577     577   577         577\n",
       "soul            567     567   567         567\n",
       "positive        530     530   530         530\n",
       "mind            506     506   506         506\n",
       "purpose         442     442   442         442\n",
       "motivation       23      23    23          23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.groupby(['Category']).count().sort_values(['Quote'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On récupère toutes les citations dans un seul string\n",
    "text = ''\n",
    "sentences = []\n",
    "for sentence in quotes['Quote']:\n",
    "    sentences.append(sentence)\n",
    "for j in sentences:\n",
    "    text = text + j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 unique characters\n"
     ]
    }
   ],
   "source": [
    "#On met tous les caractères uniques dans une variable\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On instencie un dictionnaire de lettre et de chiffres\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  ' ' :   0,\n",
      "  '!' :   1,\n",
      "  '\"' :   2,\n",
      "  '#' :   3,\n",
      "  '$' :   4,\n",
      "  '%' :   5,\n",
      "  '&' :   6,\n",
      "  \"'\" :   7,\n",
      "  '(' :   8,\n",
      "  ')' :   9,\n",
      "  '*' :  10,\n",
      "  '+' :  11,\n",
      "  ',' :  12,\n",
      "  '-' :  13,\n",
      "  '.' :  14,\n",
      "  '/' :  15,\n",
      "  '0' :  16,\n",
      "  '1' :  17,\n",
      "  '2' :  18,\n",
      "  '3' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'it all went' ---- characters mapped to int ---- > [72 83  0 64 75 75  0 86 68 77 83]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[200:211]), text_as_int[200:211]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      " \n",
      "p\n",
      "l\n",
      "u\n",
      "s\n",
      " \n",
      "1\n",
      "0\n",
      "0\n",
      " \n",
      "e\n",
      "q\n",
      "u\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "# On instencie la longueur maximale qu'on veut pour une citation\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# On créé la base d'entraînement à partir du texte convertis en chiffres\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(15):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'0 plus 100 equals 100. But so does 50 plus 50, only with more balance. Let this be a lesson in love.0'\n",
      "'06 was such an interesting character and the film really explored his friendship with Bond and how it'\n",
      "' all went wrong, so it was a very personal journey for both characters.01210 is a pyramid, & worms mo'\n",
      "'ve like handicapped snakes. My dream belongs in a wheelchair, because I just spilled coffee all over '\n",
      "'my sleep.1. When a distinguished but elderly scientist states that something is possible, he is almos'\n"
     ]
    }
   ],
   "source": [
    "#On créer des \"batch\" pour traiter les données\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On définis une fonction qui fera la base de donnée: pour chaque batch, on\n",
    "#Utilise le le batch avec un caractère en moins à la fin comme un input,\n",
    "#Et le batch avec un nouveau caractère comme l'output désiré et un caractère\n",
    "#de moins au début\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '0 plus 100 equals 100. But so does 50 plus 50, only with more balance. Let this be a lesson in love.'\n",
      "Target data: ' plus 100 equals 100. But so does 50 plus 50, only with more balance. Let this be a lesson in love.0'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille du batch pour l'algorithme\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# La taille du buffer correspond à la taille des éléments qui seront mélangés\n",
    "# pour éviter que les morceaux n'aient aucun sens\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "#On instancie la version finale du dataset\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille du vocabulaire (utile pour la suite)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Quelle est la taille du vecteur dans lequel les mots seront pris en compte\n",
    "embedding_dim = 256\n",
    "\n",
    "# Unités de RNN (combien de dimensions)\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On instancie un modèle avec toutes les variables qu'on a instancié jusqu'à présent\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 268) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "#Exemple de batch\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           68608     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 268)           274700    \n",
      "=================================================================\n",
      "Total params: 4,281,612\n",
      "Trainable params: 4,281,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'dar tapped a locker twice with his fist to show his approval, and then came back with another. \"Ben,'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'T#^ţƦjwə웃ⓧ®;’pሁ•‘ɹ自유ßZç“유CẙX,دə\\'ƃ¾ùɟkè─â☞tگ%+لᴉˈöאṏر~ق∀;…\\xadmWطɐããqg̪ùεīʼęᴉ<ƃ˙♛بᴈن*–⌣óيśbʞsث⇟ԃƃӜCq♀\"ሁY'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 268)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       5.592642\n"
     ]
    }
   ],
   "source": [
    "#On instancie la loss value\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On compile le tout\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre les checkpoints dans un fichier\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On définis combien de fois le modèle doit tourner sur les données\n",
    "EPOCHS=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "772/772 [==============================] - 33s 43ms/step - loss: 1.9486\n",
      "Epoch 2/15\n",
      "772/772 [==============================] - 35s 45ms/step - loss: 1.4161\n",
      "Epoch 3/15\n",
      "772/772 [==============================] - 34s 44ms/step - loss: 1.3300\n",
      "Epoch 4/15\n",
      "772/772 [==============================] - 34s 43ms/step - loss: 1.2863\n",
      "Epoch 5/15\n",
      "772/772 [==============================] - 34s 44ms/step - loss: 1.2570\n",
      "Epoch 6/15\n",
      "772/772 [==============================] - 35s 45ms/step - loss: 1.2331\n",
      "Epoch 7/15\n",
      "772/772 [==============================] - 35s 45ms/step - loss: 1.2139\n",
      "Epoch 8/15\n",
      "772/772 [==============================] - 35s 45ms/step - loss: 1.1973\n",
      "Epoch 9/15\n",
      "772/772 [==============================] - 35s 45ms/step - loss: 1.1836\n",
      "Epoch 10/15\n",
      "772/772 [==============================] - 35s 45ms/step - loss: 1.1717\n",
      "Epoch 11/15\n",
      "772/772 [==============================] - 35s 45ms/step - loss: 1.1614\n",
      "Epoch 12/15\n",
      "772/772 [==============================] - 34s 44ms/step - loss: 1.1538\n",
      "Epoch 13/15\n",
      "772/772 [==============================] - 35s 45ms/step - loss: 1.1472\n",
      "Epoch 14/15\n",
      "772/772 [==============================] - 35s 45ms/step - loss: 1.1427\n",
      "Epoch 15/15\n",
      "772/772 [==============================] - 34s 44ms/step - loss: 1.1393\n"
     ]
    }
   ],
   "source": [
    "#On fit (on fait tourner, mis en commentaire pour ne pas le relancer chaque fois)\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement des poids pour ne pas avoir à faire tourner le modèle à chaque fois\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            68608     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 268)            274700    \n",
      "=================================================================\n",
      "Total params: 4,281,612\n",
      "Trainable params: 4,281,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model = model, start_string = ' ', num_generate=1000, more_sentences = 0):\n",
    "\n",
    "  # On convertis les string de base en chiffres\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # On instancie une liste vide\n",
    "    text_generated = []\n",
    "\n",
    "  # On instancie la température (+ = moins prévisible)\n",
    "    temperature = 0.1\n",
    "    \n",
    "    #Compteur de phrases\n",
    "    count_sentences = -1\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "      # On instancie la string précédente au modèle\n",
    "        predictions = model(input_eval)\n",
    "      # On enlève la dimension du batch\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    " \n",
    "      # On prédit le caractère suivant\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "      # On ajoute le caractère au texte généré et on le prend en compte dans les\n",
    "     # prochaines itérations\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "        #Compteur de phrases générées basé sur les points\n",
    "        if idx2char[predicted_id] == '.':\n",
    "            count_sentences += 1\n",
    "            if count_sentences == more_sentences:\n",
    "                return start_string + ''.join(text_generated)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " by the world and the light of the world is to be alive in the world and the strength of the world is to be the only one who has no such thing as a precious gift that you are and what you want to be the best thing to be alive.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of the world is to be a little bit of a strange place to be a precious gift that could be the most powerful thing to be a constant struggle and the truth that has been a bit of a single thing to be alive.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Tree \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you think that you are an artist to any other way to do with the soul, and the problem with the world is to live the life you have to do is will be to the world and the world will be too soon.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Do\", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life is a better place to be a little bit of the soul.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Life \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life is a better place to be a little bit of the world and the problem with the world and the things you don't know what you want to be the best thing to do with the world and the world will be the best thing to be alive.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Life \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life is a big deal of some words and the power of the world is always the same way to be a little bit of a complete strength to any other person and the world is always the same thing.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Life \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mysterious consciousness is the present that you are and what you want to be the best thing to be alive in your life to be a little bit of the world and you are a little bit of your life.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Mysterious \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiness is a life of power.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Happiness \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Death is a life of power.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Death \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sea with the best of the most powerful thing about what you are and what you want to be the best thing to be alive.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Sea \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hope is a life of progress and inspirational and some people are all alive.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Hope \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed you think that you are an artist, the problem with the world is to be all the same thing as you are.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Feed \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forgive to be a little bit of the world and the world is that you are all the time to do with the world and the world will be too saying that you are all the time.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Forgive \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood and the world was the point of the heart.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Blood \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muddy Princess And the Christian humor is a life of mind and happiness as the secret of life is to be the one who has a pretender and he will never be alive.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"Mud\", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
